1，	进程和线程 
进程是程序向操作系统申请资源的基本单位
线程是进程中可独立执行的最小单位
2，	关于事务http://heavy_code_industry.gitee.io/code_heavy_industry/pro015-Distributed-Transaction/
事务的特性ACID
原子性 Atomicity   
    一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，事务在执行过程中发生错误，会被回滚到事务开始前的状态
一致性 Consistency
   一个事务在执行之前和执行之后数据库都必须处于一致性状态
   隔离性Isolation
       指的是并发环境中，当不同的事务同时操作操纵相同的数据时，每个事务都有各自的完整数据空间，由并发事务所作的修改必须与其他并发事务所有的修改隔离，事务查看数据更新时，数据所处状态要么时另一事务修改它之前的状态，要么时另一事务修改它之后的状态，事务不会查看到中间状态的数据
持久性Durability
    事务只要成功结束，它对数据库所做的更新就必须保存下载，即使发生系统崩溃，重启启动数据库系统后，数据库还能恢复到事务成功结束时的状态

为什么会导致分布式事务
原因：
1，单个节点内部操作失败，导致我们从整个系统的视角来，数据进入不一致
3，	网络传输失败，导致我们无法确认某个节点的操作是否得到执行
从微观角度来看：造成分布式事务问题的这两个基本因素无法彻底消除

3,分布式事务标准
   CAP定理
      一致性（Consistency）（对）   数据在多个副本之间能保持一致特性
      可用性（Available）（快）     系统提供的服务一直处于可用的状态，每次只要收到用户的请求，服务器就必须给出回应，在合理的时间内返回合理的相应---不是错误和超时的相应
      分区容错性（Partition Toleration）（能用）即使各个子网络无法通信，甚至某个分区出现故障，但整个系统对外仍然可用的
   BASE定理
      BASE = Bsaically Available（基本可用） + Soft state（软状态）+ Eventually consistent（最终一致性）

解决方案；
基于XA协议的两阶段提交（2PC）
1，	XA协议：XA是一个分布式事务协议。XA中大致分为两部分：事务管理器和本地资源管理器。其中本地资源管理器往往由数据库实现，比如Oracle、DB2这些商业数据库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚
二阶段提交2PC（Two phase Commit）是指，在分布式系统里，为了保证所有节点在进行事务提交时保持一致性的一种算法
2PC顾名思义分为两个阶段，其实施思路可概括为：
（1）投票阶段（voting phase）：参与者将操作结果通知协调者；
（2）提交阶段（commit phase）：收到参与者的通知后，协调者再向参与者发出通知，根据反馈情况决定各参与者是否要提交还是回滚；

•	2PC两阶段提交究竟有哪些不足呢？
1)性能问题
2PC遵循强一致性。在事务执行过程中，各个节点占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知提交，参与者提交后释放资源。这样的过程有着非常明显的性能问题。
2) 协调者单点故障问题
协调者是整个2PC模型的核心，一旦事务协调者节点挂掉，参与者收不到提交或是回滚通知，参与者会一直处于中间状态无法完成事务。
3) 丢失消息导致的不一致问题。
的第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。
代码补偿事务(TCC）

TCC 的作用主要是解决跨服务调用场景下的分布式事务问题
优点： 跟2PC(很多第三方框架)比起来，实现以及流程相对简单了一些，但数据的一致性比2PC也要差一些
缺点： 缺点还是比较明显的，在2,3步中都有可能失败。TCC属于应用层的一种补偿方式，所以需要程序员在实现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处理。
本地消息表（异步确保）- 事务最终一致性

其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。如果不考虑性能及设计优雅，借助关系型数据库中的表即可实现。

通常采用两种方式：

1，采用时效性高的 MQ，由对方订阅消息并监听，有消息时自动触发事件
2，	采用定时轮询扫描的方式，去检查消息表的数据
3，	两种方式其实各有利弊，仅仅依靠 MQ，可能会出现通知失败的问题。而过于频繁的定时轮询，效率也不是最佳的（90% 是无用功）。所以，我们一般会把两种方式结合起来使用。
4，	解决了通知的问题，又有新的问题了。万一这消息有重复被消费，往用户帐号上多加了钱，那岂不是后果很严重？
5，	仔细思考，其实我们可以在消息消费方，也通过一个“消费状态表”来记录消费状态。在执行“加款”操作之前，检测下该消息（提供标识）是否已经消费过，消费完成后，通过本地事务控制来更新这个“消费状态表”。这样子就避免重复消费的问题。
6，	总结：上述的方式是一种非常经典的实现，基本避免了分布式事务，实现了“最终一致性”。但是，关系型数据库的吞吐量和性能方面存在瓶颈，频繁的读写消息会给数据库造成压力。所以，在真正的高并发场景下，该方案也会有瓶颈和限制的。


•	执行流程：
o	订单系统，添加一条订单和一条消息，在一个事务里提交。
o	订单系统，使用定时任务轮询查询状态为未同步的消息表，发送到 MQ，如果发送失败，就重试发送。
o	库存系统，接收 MQ 消息，修改库存表，需要保证幂等操作。
o	如果修改成功，调用 RPC 接口修改订单系统消息表的状态为已完成或者直接删除这条消息。
o	如果修改失败，可以不做处理，等待重试。
o	订单系统中的消息有可能由于业务问题会一直重复发送，所以为了避免这种情况可以记录一下发送次数，当达到次数限制之后报警，人工接入处理；库存系统需要保证幂等，避免同一条消息被多次消费造成数据不一致。
o	本地消息表这种方案实现了最终一致性，需要在业务系统里增加消息表，业务逻辑中多一次插入的 DB 操作，所以性能会有损耗，而且最终一致性的间隔主要由定时任务的间隔时间决定。
•	优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。在 .NET中有现成的解决方案。
•	缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。
MQ 事务消息

有一些第三方的MQ是支持事务消息的，比如RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交，但是市面上一些主流的MQ都是不支持事务消息的，比如 RabbitMQ 和 Kafka 都不支持，但是Rabbit MQ可以通过可靠消息投递来实现事务消息。


Seata原理：http://www.dreamwu.com/post-1741.html
重要机制

（1）全局事务的回滚是如何实现的呢？

Seata 有一个重要的机制：回滚日志。

每个分支事务对应的数据库中都需要有一个回滚日志表 UNDO_LOG，在真正修改数据库记录之前，都会先记录修改前的记录值，以便之后回滚。

在收到回滚请求后，就会根据 UNDO_LOG 生成回滚操作的 SQL 语句来执行。

如果收到的是提交请求，就把 UNDO_LOG 中的相应记录删除掉。

（2）RM 是怎么自动和 TC 交互的？

是通过监控拦截JDBC实现的，例如监控到开启本地事务了，就会自动向 TC 注册、生成回滚日志、向 TC 汇报执行结果。

（3）二阶段回滚失败怎么办？

例如 TC 命令各个 RM 回滚的时候，有一个微服务挂掉了，那么所有正常的微服务也都不会执行回滚，当这个微服务重新正常运行后，TC 会重新执行全局回滚。

1.3 核心组件

回顾一下其中的核心组件：

事务协调器 TC
维护全局和分支事务的状态，指示全局提交或者回滚。

事务管理者 TM
开启、提交或者回滚一个全局事务。

资源管理者 RM
管理执行分支事务的那些资源，向TC注册分支事务、上报分支事务状态、控制分支事务的提交或者回滚。


JVM
类加载过程，
类加载器分为四种：前三种为虚拟机自带的加载器。
•	启动类加载器（Bootstrap）：使用 C++ 语言编写的类加载器，在Java环境下看不到
负责加载 $JAVA_HOME/jre/lib/rt.jar 里所有的 class。由 C++ 实现，不是 ClassLoader 子类
•	扩展类加载器（Extension）：sun.misc.Launcher.ExtClassLoader
负责加载 Java 平台中扩展功能的一些 jar 包，包括 $JAVA_HOME/jre/lib/*.jar 或 -Djava.ext.dirs 参数指定目录下的 jar 包、以及 $JAVA_HOME/jre/lib/ext/classes 目录下的 class。
•	应用类加载器（AppClassLoader）：sun.misc.Launcher.AppClassLoader
也叫系统类加载器，负责加载classpath中指定的 jar 包及目录中的 class
•	自定义类加载器：程序员自己开发一个类继承 java.lang.ClassLoader，定制类加载方式
父子关系1：启动类加载器是扩展类加载器的父加载器
父子关系2：扩展类加载器是应用类加载器的父加载器
双亲委派机制
•	避免类的重复加载：父加载器加载了一个类，就不必让子加载器再去查找了。同时也保证了在整个 JVM 范围内全类名是类的唯一标识。
•	安全机制：避免恶意替换 JRE 定义的核心 API

1、	本地接口 Native Interface
本地接口的作用是融合不同的编程语言为 Java 所用，因为 Java 诞生的时候是 C/C++ 横行的时候，要想立足，必须有能力调用 C/C++。于是就在内存中专门开辟了一块区域处理标记为 native 的代码，它的具体做法是 Native Method Stack 中登记 native 方法，在Execution Engine 执行时加载 native libraies。
目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过 Java 程序驱动打印机或者 Java 系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用 Socket 通信，也可以使用 Web Service 等等
2、	本地方法栈 Native Method Stack
专门负责在本地方法运行时，提供栈空间，存放本地方法每一次执行时创建的栈帧。它的具体做法是在 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库。
native 方法举例：public static native void yield();
3，程序计数器
也叫PC寄存器（Program Counter Register）。用于保存程序执行过程中，下一条即将执行的指令的地址。也就是说能够保存程序当前已经执行到的位置。这个位置由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记
4，执行引擎 Execution Engine
作用：用于执行字节码文件中的指令。
执行指令的具体技术：
•	解释执行：第一代JVM。
•	即时编译：JIT，第二代JVM。
•	自适应优化：目前Sun的Hotspot JVM采用这种技术。吸取了第一代JVM和第二代JVM的经验，在一开始的时候对代码进行解释执行， 同时使用一个后台线程监控代码的执行。如果一段代码经常被调用，那么就对这段代码进行编译，编译为本地代码，并进行执行优化。若方法不再频繁使用，则取消编译过的代码，仍对其进行解释执行。
•	芯片级直接执行：内嵌在芯片上，用本地方法执行Java字节码。
5，直接内存
①作用
提高特定场景下性能。
#②应用场景
直接内存并不是虚拟机运行时数据区的一部分，也不是Java 虚拟机规范中定义的内存区域。在JDK1.4 中新加入了NIO(New Input/Output)类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 本机直接内存的分配不会受到 Java 堆大小的限制，受到本机总内存大小限制。 配置虚拟机参数时，不要忽略直接内存防止出现 OutOfMemoryError 异常。
#③直接内存（堆外内存）与堆内存比较
直接内存申请空间耗费更高的性能，当频繁申请到一定量时尤为明显。直接内存 I/O 读写的性能要优于普通的堆内存，在多次读写操作的情况下差异明显。

6，方法区
标准层面：方法区（Method Area）
具体实现层面：
≤1.6 永久代
=1.7 永久代仍然存在，但是已经开始提出：去永久代
≥1.8元空间（Meta Space）

元空间存储数据说明
类信息：类中定义的构造器、接口定义
静态变量（类变量）
常量
运行时常量池
类中方法的代码
7，	栈
方法栈并不是某一个 JVM 的内存空间，而是我们描述方法被调用过程的一个逻辑概念
1、栈帧存储的数据
方法在本次执行过程中所用到的局部变量、动态链接、方法出口等信息。栈帧中主要保存3 类数据：
本地变量（Local Variables）：输入参数和输出参数以及方法内的变量。
栈操作（Operand Stack）：记录出栈、入栈的操作。
栈帧数据（Frame Data）：包括类文件、方法等等。
2、栈帧的结构
局部变量表：方法执行时的参数、方法体内声明的局部变量
操作数栈：存储中间运算结果，是一个临时存储空间
帧数据区：保存访问常量池指针，异常处理表
3、栈帧工作机制
先进后出
每执行一个方法都会产生一个栈帧，保存到栈的顶部，顶部栈就是当前方法，该方法执行完毕后会自动将此栈帧出栈

java.lang.StackOverflowErro
原因总结：方法每一次调用都会在栈空间中申请一个栈帧，来保存本次方法执行时所需要用到的数据。但是一个没有退出机制的递归调用，会不断申请新的空间，而又不释放空间，这样迟早会把当前线程在栈内存中自己的空间耗尽

8，堆
1，堆空间工作机制
新创建的对象会被放在Eden区
当Eden区中已使用的空间达到一定比例，会触发Minor GC
每一次在Minor GC中没有被清理掉的对象就成了幸存者
幸存者对象会被转移到幸存者区
幸存者区分成from区和to区
from区快满的时候，会将仍然在使用的对象转移到to区
然后from和to这两个指针彼此交换位置
口诀：复制必交换，谁空谁为to
如果一个对象，经历15次GC仍然幸存，那么它将会被转移到老年代
如果幸存者区已经满了，即使某个对象尚不到15岁，仍然会被移动到老年代
最终效果：
Eden区主要是生命周期很短的对象来来往往
老年代主要是生命周期很长的对象，例如：IOC容器对象、线程池对象、数据库连接池对象等等
幸存者区作为二者之间的过渡地带
关于永久代：
从理论上来说属于堆
从具体实现上来说不属于堆
2,堆溢出异常
java.lang.OutOfMemoryError，也往往简称为 OOM
Java heap space：针对新生代、老年代整体进行Full GC后，内存空间还是放不下新产生的对象
PermGen space：方法区中加载的类太多了（典型情况是框架创建的动态类太多，导致方法区溢出）


9,垃圾回收
为什么要GC？
服务器运行的时间通常都很长。累积的对象也会非常多。这些对象如果不做任何清理，任由它们数量不断累加，内存很快就会耗尽。所以GC就是要把不使用的对象都清理掉，把内存空间空出来，让项目可以持续运行下去。

什么样的对象是垃圾对象？
不再使用或获取不到的对象是垃圾对象。

如何把垃圾对象找出来？
办法1：引用计数法（不采用，不能解决循环引用问题）
办法2：可达性分析（从GC Roots对象出发，不可达的对象就是要清理的对象）

找到垃圾对象如何执行清理？
具体的GC算法

1,如何把垃圾对象找出来？
1,引用计数法（不采用）
引用计数法是在对象每一次被引用时，都给这个对象专属的『引用计数器』+1。
当前引用被取消时，就给这个『引用计数器』-1。
当前『引用计数器』为零时，表示这个对象不再被引用了，需要让GC回收。
可是当对象之间存在交叉引用的时候，对象即使处于应该被回收的状态，也没法让『引用计数器』归零

2,GC Roots可达性分析
核心原理：判断一个对象，是否存在从『堆外』到『堆内』的引用

GC Root 对象
GC Root 对象：就是作为根节点出发，顺着引用路径一直查找到堆空间内，找到堆空间中的对象。
Java 栈中的局部变量
本地方法栈中的局部变量
方法区中的类变量、常量
2,垃圾回收算法
基本垃圾回收算法有四种：引用计数法、标记清除法、标记压缩法、复制算法。现代流行的垃圾收集算法一般是由这四种中的其中几种算法相互组合而成。例如：分代算法、分区算法。
1、基本算法：引用计数法
优点：
实时性较高，不需要等到内存不够时才回收
垃圾回收时不用挂起整个程序，不影响程序正常运行
缺点：
回收时不移动对象, 所以会造成内存碎片问题
不能解决对象间的循环引用问题
小结：
正是由于引用计数法不能解决对象间的循环引用问题，所以事实上并没有哪一款 JVM 产品采用这个机制。
2,基本算法：标记清除法
它的做法是当堆中的有效内存空间被耗尽的时候，就会暂停、挂起整个程序（也被称为stop the world），然后进行两项工作，第一项则是标记，第二项则是清除。
•	标记：标记的过程其实就是，从根对象开始遍历所有的对象，然后将所有存活的对象标记为可达的对象。
•	清除：清除的过程将遍历堆中所有的对象，将没有标记的对象全部清除掉。
小结：
•	优点：实现简单
•	缺点：
o	效率低，因为标记和清除两个动作都要遍历所有的对象
o	垃圾收集后有可能会造成大量的内存碎片
o	垃圾回收时会造成应用程序暂停
3, 基本算法：标记压缩法
既然叫标记压缩算法，那么它也分为两个阶段，一个是标记(mark)，一个是压缩(compact)。所谓压缩就是把存在碎片的空间连起来。
标记压缩算法是在标记清除算法的基础之上，做了优化改进的算法。和标记清除算法一样，也是从根节点开始，对对象的引用进行标记，在清理阶段，并不是简单的清理未标记的对象，而是将存活的对象移动到内存的一端，然后清理边界以外的垃圾，从而解决了碎片化的问题。
标记 : 标记的过程其实就是，从根对象开始遍历所有的对象，然后将所有存活的对象标记为可达的对象。
压缩 : 移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到减少内存碎片的目的。
小结
优点：标记压缩算法是对标记清除算法的优化，解决了碎片化的问题
缺点：还是效率问题，在标记清除算法上又多加了一步，效率可想而知了
4, 基本算法：复制算法
复制算法的核心就是，将原有的内存空间一分为二，每次只用其中的一块，在垃圾回收时，将正在使用的对象复制到另一个内存空间中，并依次排列，然后将该内存空间清空，交换两个内存的角色，完成垃圾的回收。
小结
优点1：在垃圾多的情况下(新生代)，效率较高
优点2：清理后，内存无碎片
缺点：浪费了一半的内存空间，在存活对象较多的情况下(老年代)，效率较差
5、综合算法：分代算法
前面介绍了多种回收算法，每一种算法都有自己的优点也有缺点，谁都不能替代谁，所以根据垃圾回收对象的特点进行选择，才是明智的。
分代算法其实就是这样的，根据回收对象的特点进行选择。
新生代适合使用复制算法
老年代适合使用标记清除或标记压缩算法
6、综合算法：分区算法
上面介绍的分代收集算法是将对象的生命周期按长短划分为两个部分，而分区算法则将整个堆空间划分为连续的不同小区间，每个小区间独立使用，独立回收。这样做的好处是可以控制一次回收多少个小区间。在相同条件下，堆空间越大。一次GC耗时就越长，从而产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割为多个小块，根据目标停顿时间每次合理地回收若干个小区间(而不是整个堆)，从而减少一次GC所产生的停顿。
3,垃圾回收器 [了解]
1、串行垃圾回收器
串行：在一个线程内执行垃圾回收操作。
新生代串行回收器 SerialGC：采用复制算法实现，单线程垃圾回收，独占式垃圾回收器
老年代串行回收器 SerialOldGC：采用标记压缩算法，单线程独占式垃圾回收器
2、并行垃圾回收器
并行：在多个线程中执行垃圾回收操作。
新生代 parNew 回收器：采用复制算法实现，多线程回收器，独占式垃圾回收器。
新生代 ParallelScavengeGC 回收器：采用复制算法多线程独占式回收器
老年代 ParallelOldGC 回收器: 采用标记压缩算法，多线程独占式回收器
CMS回收器
CMS全称 (Concurrent Mark Sweep)，是一款并发的、使用标记-清除算法的垃圾回收器。对CPU资源非常敏感。
启用CMS回收器参数 ：-XX:+UseConcMarkSweepGC。
使用场景：GC过程短暂停顿，适合对时延要求较高的服务，用户线程不允许长时间的停顿。
优点：最短回收停顿时间为目标的收集器。并发收集，低停顿。
缺点：服务长时间运行，造成严重的内存碎片化。算法实现比较复杂。
G1回收器
G1(Garbage-First)是一款面向服务端应用的并发垃圾回收器, 主要目标用于配备多颗CPU的服务器，治理大内存。是JDK1.7提供的一个新收集器，是当今收集器技术发展的最前沿成果之一。
G1计划是并发标记-清除收集器的长期替代品。
启用G1收集器参数：-XX:+UseG1GC启用G1收集器。
G1将整个Java堆划分为多个大小相等的独立区域(Region)，虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了, 它们都是一部分Region(不需要连续)的集合。

JUC
1,

wait()	sleep()
声明位置	Object 类	Thread 类
作用对象	作用于调用 wait() 方法的对象	作用于当前线程
性质	非静态方法	静态方法
释放锁资源	放开锁进入等待	不释放锁进入等待
同步要求	必须在同步上下文中使用	不要求在同步上下文中



在 JDK 1.6 之前，synchronized 的底层工作机制只有『重量级锁』这一种模式。从 JDK 1.6 开始，官方对synchronized 的底层工作机制做了重大调整。
为了减少获得锁和释放锁带来的性能消耗，引入了『偏向锁』和『轻量级锁』的概念。升级后锁一共有 4 种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。锁可以升级但不能降级，也称为膨胀过程不可逆。
面试整理
极兔速递
1，项目中用到哪些springcloud组件
SpringCloud中的常用组件有哪些？
Spring Cloud的子项目很多，比较常见的都是Netflix开源的组件：

Spring Cloud Config
集中配置管理工具，分布式系统中统一的外部配置管理，默认使用Git来存储配置，可以支持客户端配置的刷新及加密、解密操作。

Spring Cloud Netflix
Netflix OSS 开源组件集成，包括Eureka、Hystrix、Ribbon、Feign、Zuul等核心组件。

Eureka：服务治理组件，包括服务端的注册中心和客户端的服务发现机制；
Ribbon：负载均衡的服务调用组件，具有多种负载均衡调用策略；
Hystrix：服务容错组件，实现了断路器模式，为依赖服务的出错和延迟提供了容错能力；
Feign：基于Ribbon和Hystrix的声明式服务调用组件；
Zuul：API网关组件，对请求提供路由及过滤功能。
Spring Cloud Bus
用于传播集群状态变化的消息总线，使用轻量级消息代理链接分布式系统中的节点，可以用来动态刷新集群中的服务配置。

Spring Cloud Consul
基于Hashicorp Consul的服务治理组件。

Spring Cloud Security
安全工具包，对Zuul代理中的负载均衡OAuth2客户端及登录认证进行支持。

Spring Cloud Sleuth
Spring Cloud应用程序的分布式请求链路跟踪，支持使用Zipkin、HTrace和基于日志（例如ELK）的跟踪。

Spring Cloud Stream
轻量级事件驱动微服务框架，可以使用简单的声明式模型来发送及接收消息，主要实现为Apache Kafka及RabbitMQ。

Spring Cloud Task
用于快速构建短暂、有限数据处理任务的微服务框架，用于向应用中添加功能性和非功能性的特性。

Spring Cloud Zookeeper
基于Apache Zookeeper的服务治理组件。

Spring Cloud Gateway
API网关组件，对请求提供路由及过滤功能。

Spring Cloud OpenFeign
基于Ribbon和Hystrix的声明式服务调用组件，可以动态创建基于Spring MVC注解的接口实现用于服务调用，在Spring Cloud 2.0中已经取代Feign成为了一等公民。、

SpringCloud与Dubbo的区别
两者都是现在主流的微服务框架，但却存在不少差异：

初始定位不同：SpringCloud定位为微服务架构下的一站式解决方案；Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用和治理
生态环境不同：SpringCloud依托于Spring平台，具备更加完善的生态体系；而Dubbo一开始只是做RPC远程调用，生态相对匮乏，现在逐渐丰富起来。
调用方式：SpringCloud是采用Http协议做远程调用，接口一般是Rest风格，比较灵活；Dubbo是采用Dubbo协议，接口一般是Java的Service接口，格式固定。但调用时采用Netty的NIO方式，性能较好。
组件差异比较多，例如SpringCloud注册中心一般用Eureka，而Dubbo用的是Zookeeper
SpringCloud生态丰富，功能完善，更像是品牌机，Dubbo则相对灵活，可定制性强，更像是组装机。相关资料：

SpringCloud：Spring公司开源的微服务框架，SpirngCloud 定位为微服务架构下的一站式解决方案。

Dubbo：阿里巴巴开源的RPC框架，Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断

SpringCloudAlibaba
 

 



2，springcloudgateway和spirngcloudzuul区别
   Gateway比zuul多依赖了spring-webflux,内部实现限流，负载均衡等，扩展性更强，但仅限于spirngcloud组件，zuul则可以扩展至其他微服务框架中，其内部没有实现限流，负载均衡等
   Zuul仅支持同步，gateway支持异步
   Gateway线程开销少，支持各种长链接，websocket，spring官方支持，但运维复杂，zuul编程模型简单，开发调试运维简单，有线程数限制，延迟堵塞会耗尽线程池连接资源
   
3，Threadlocal
是什么？
ThreadLocal 则采用了一种完全不同的策略，它不是用来解决共享数据的并发访问问题的，ThreadLocal 让每个线程都将目标数据复制一份作为线程私有，后续对于该数据的操作都是在各自私有的副本上进行，线程之间彼此相互隔离，也就不存在竞争问题。
怎么用？
Threadlocal的使用
实践：如果多线程情况，simpleDateFormat类是线程不安全的，我们可以用ThreadLocal进行包装，以保证每个线程都有属于自己的SimpleDateFormat对象
原理
在ThreadLocal怎么做到每个线程中各自持有一份呢？
在ThreadLocal内部定义了一个静态内部类ThreadLocalMap，可以将其理解为一个特有的Map类型，而在Thread类中声明了一个ThreadLocalMap类型的threads属性，针对每个Thread对象，也就是每个线程来说都包含一个ThreadLocalMap对象，即每个线程都拥有一个属于自己的内存数据库，而数据库的存储的就是我们用Threadocal修饰的对象，
 
这里的key是ThreadLocal对象自身，value是ThreadLocal修饰的属性值，当希望获取该对象时，我们首先需要拿到当前线程的Thread对象，然后获取对应的threadLocals属性，也就拿到了线程私有的内存数据库，最后以ThreadLoca对象为key获取到其修饰的目标值
线程内存数据库
ThreadLocalMap是一个定制化的Map实现，用作键值存储的内存数据库，为什么复用Hashmap呢？
原因：1，get,set方法不需要专门指定key,能够一定程度上简化使用
      2，ThreadLocalMap在实现Entry的时候，集成weakReference，从而让key成为一个弱引用，gc的时候，一旦发现弱引用，不管当前内存空间是否足够，都会回收它的内存，这样设计很容易导致ThreadLoca对象被回收，线程所执行任务的时间长度不固定的，这样设计能够方便垃圾收集器回收回收线程的私有变量

对于ThreadLocal来说对外，提供get，set，remove方法
获取线程私有值，Get方法并没有要求提供查询的key,因为这里的key就是threadloca对象自身
如果当前线程对应的内存数据库map对象还未创建，则会调用Threadlocal的setInitiavalue方法执行创建，如果在构造Thredlocal对象覆盖实现了initiaValue方法，则会调用该方法获取构造的初始化值并记录到创建的map对象中
设置线程私有值，set方法不需要指定key,都是操作当前线程私有的内存数据库ThreadLocalMap，并记录目标值
删除线程私有值，以当前ThreadLocal对象为key，从当前线程内存数据库ThreadLocaMap中删除目标值
   Threadlocal思考：
  	Threadlocal本质上就是为每隔线程维护一个线程私有的内存数据库来记录线程私有的对象，但是在这个线程池情况下，会被复用的，也就是说线程私有的内存数据库也会被复用，如果一个线程被使用完准备回放到线程池之前，我们没有对记录在数据库中的数据库执行清理，那么这部分数据就会被下一个复用线程的业务看到，从而间接的共享了该部分数据
   会内存泄漏吗
      如果使用不当会存在内存泄漏的可能性，如果value是一个强引用没有被回收，这些value就会变成一个个的僵尸，value确实存在且和线程同生命周期，并且使用线程没有调用get,set方法，导致不会主动删除key为null的value，这两个条件下，存在内存泄漏的可能性
如下策略可以避免内存泄漏：
  1，Threadlocal每次get和set操作的额时候都会清理key为null的value值
  2，value与线程同生命周期，线程死亡的时候，value也是被gc之日
实践的时候如何避免呢？
  内存泄漏一般也是发生在线程池的情况下，所以在使用ThreadLoca时，对于不在有效的value，主动调用一下，remove方法来进行请吃，从而消除隐患
	 InheritableThreadLocal 类		
     子线程的初始化，会判断父线程InheritableThreadLocals变量是否为null，如果不为null,则用父类的InheritableThreadLocals初始化为自己的InheritableThreadLocals，本质上就是拷贝父线程的一个变量值的过程，父线程和子线程的Threadlocal变量的存储上仍是隔离的，只是初始化的时候，会拷贝父类的，之后的运行互不干涉，互相的改动并不会被对方看到
4，volatile如何实现
使用 volatile 和 synchronized 锁都可以保证共享变量的可见性。相比 synchronized 而言，volatile 可以看作是一个轻量级锁，所以使用 volatile 的成本更低，因为它不会引起线程上下文的切换和调度。但 volatile 无法像 synchronized 一样保证操作的原子性。
作用：
1,保证变量内存可见性
使用 volatile 修饰共享变量后，每个线程要操作变量时会从主内存中将变量拷贝到本地内存作为副本，当线程操作变量副本并写回主内存后，会通过 CPU 总线嗅探机制告知其他线程该变量副本已经失效，需要重新从主内存中读取。
volatile 保证了不同线程对共享变量操作的可见性，也就是说一个线程修改了 volatile 修饰的变量，当修改后的变量写回主内存时，其他线程能立即看到最新值
嗅探机制工作原理：每个处理器通过监听在总线上传播的数据来检查自己的缓存值是不是过期了，如果处理器发现自己缓存行对应的内存地址修改，就会将当前处理器的缓存行设置无效状态，当处理器对这个数据进行修改操作的时候，会重新从主内存中把数据读到处理器缓存中。
 

2，禁止指令重排序
 
内存屏障指令是一组处理器指令，作用是禁止指令重排序和解决内存可见性的问题
volatile 读 / 写插入内存屏障规则：
•	在每个 volatile 读操作的后面插入 LoadLoad 屏障和 LoadStore 屏障。
•	在每个 volatile 写操作的前后分别插入一个 StoreStore 屏障和一个 StoreLoad 屏障。
也就是说，编译器不会对 volatile 读与 volatile 读后面的任意内存操作重排序；编译器不会对 volatile 写与 volatile 写前面的任意内存操作重排序。
•	volatile 修饰符适用于以下场景：某个属性被多个线程共享，其中有一个线程修改了此属性，其他线程可以立即得到修改后的值；或者作为状态变量，如 flag = ture，实现轻量级同步。
•	volatile 属性的读写操作都是无锁的，它不能替代 synchronized，因为它没有提供原子性和互斥性。因为无锁，不需要花费时间在获取锁和释放锁上，所以说它是低成本的。
•	volatile 只能作用于属性，我们用 volatile 修饰属性，这样编译器就不会对这个属性做指令重排序。
•	volatile 提供了可见性，任何一个线程对其的修改将立马对其他线程可见。volatile 属性不会被线程缓存，始终从主存中读取。
•	volatile 提供了 happens-before 保证，对 volatile 变量 V 的写入 happens-before 所有其他线程后续对 V 的读操作。
•	volatile 可以使纯赋值操作是原子的，如 boolean flag = true; falg = false。
•	volatile 可以在单例双重检查中实现可见性和禁止指令重排序，从而保证安全性。

5，AQS
AbstracQueuedSynchronizer 抽象队列同化器，简称AQS,
6，CAS
Conmpare And Swap  比较和交换
实现多线程同步的原子指令
 CAS 其实是一个乐观锁
CAS的核心是在将B值写入到V之前要比较A值和V值是否相同，如果不相同证明此时V值已经被其他线程改变，重新将V值赋给A，并重新计算得到B，如果相同，则将B值赋给V。
JAVA 的 cas 是怎么实现的：
•	java 的 cas 利用的的是 unsafe 这个类提供的 cas 操作。
•	unsafe 的cas 依赖了的是 jvm 针对不同的操作系统实现的 Atomic::cmpxchg
•	Atomic::cmpxchg 的实现使用了汇编的 cas 操作，并使用 cpu 硬件提供的 lock信号保证其原子性
什么是总线风暴，先来看结论
在java中使用unsafe实现cas,而其底层由cpp调用汇编指令实现的，如果是多核cpu是使用lock cmpxchg指令，单核cpu 使用compxch指令。如果在短时间内产生大量的cas操作在加上 volatile的嗅探机制则会不断地占用总线带宽，导致总线流量激增，就会产生总线风暴。 总之，就是因为volatile 和CAS 的操作导致BUS总线缓存一致性流量激增所造成的影响
了解过volatile和cas 的朋友都知道由于一个变量在多个高速缓存中都存在，但由于高速缓存间的数据是不共享的，所以势必会有数据不一致的问题，为了解决这种问题处理器是通过总线锁定和缓存锁定这两个机制来保证复杂内存操作的原子性的。

1、总线锁
在早期处理器提供一个 LOCK# 信号，CPU1在操作共享变量的时候会预先对总线加锁，此时CPU2就不能通过总线来读取内存中的数据了，但这无疑会大大降低CPU的执行效率。
2、缓存一致性协议
由于总线锁的效率太低所以就出现了缓存一致性协议，Intel 的MESI协议就是其中一个佼佼者。MESI协议保证了每个缓存变量中使用的共享变量的副本都是一致的

3、MESI 的核心思想
modified（修改）、exclusive（互斥）、share（共享）、invalid（无效）
如上图，CPU1使用共享数据时会先数据拷贝到CPU1缓存中,然后置为独占状态(E)，这时CPU2也使用了共享数据，也会拷贝也到CPU2缓存中。通过总线嗅探机制，当该CPU1监听总线中其他CPU对内存进行操作，此时共享变量在CPU1和CPU2两个缓存中的状态会被标记为共享状态(S)；
若CPU1将变量通过缓存回写到主存中，需要先锁住缓存行，此时状态切换为（M），向总线发消息告诉其他在嗅探的CPU该变量已经被CPU1改变并回写到主存中。接收到消息的其他CPU会将共享变量状态从（S）改成无效状态（I），缓存行失效。若其他CPU需要再次操作共享变量则需要重新从内存读取。
缓存一致性协议失效的情况：
•	共享变量大于缓存行大小，MESI无法进行缓存行加锁；
•	CPU并不支持缓存一致性协议
4、嗅探机制
每个处理器会通过嗅探器来监控总线上的数据来检查自己缓存内的数据是否过期，如果发现自己缓存行对应的地址被修改了，就会将此缓存行置为无效。当处理器对此数据进行操作时，就会重新从主内存中读取数据到缓存行。
5、缓存一致性流量
通过前面都知道了缓存一致性协议，比如MESI会触发嗅探器进行数据传播。当有大量的volatile 和cas 进行数据修改的时候就会产大量嗅探消息。

三、总结性言论
通过上面一顿巴拉，大家应该对开局图有一定的了解了，也大概知道了总线风暴的原因。这里再做一下概括性的总结（当前内部还有很有详细的机制，大家感兴趣可以撸一波）
在多核处理器架构上，所有的处理器是共用一条总线的，都是靠此总线来和主内存进行数据交互。当主内存的数据同时存在于多个处理的高速缓存中时，某一处理器更新了此共享数据后。会通过总线触发嗅探机制来通知其他处理器将自己高速缓存内的共享数据置为无效，在下次使用时重新从主内存加载最新数据。而这种通过总线来进行通信则称之为”缓存一致性流量“。
因为总线是固定的，所有相应可以接受的通信能力也就是固定的了，如果缓存一致性流量突然激增，必然会使总线的处理能力受到影响。而恰好CAS和volatile 会导致缓存一致性流量增大。如果很多线程都共享一个变量，当共享变量进行CAS等数据变更时，就有可能产生总线风暴。


7.ABA 问题
什么是”ABA”问题？
比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。
尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。
 
用AtomicStampedReference/AtomicMarkableReference解决ABA问题

8，springcloud如何实现链路追踪
分布式链路追踪 
Spring Cloud Sleuth 主要功能就是在分布式系统中提供追踪解决方案，并且兼容支持了 zipkin，你只需要在pom文件中引入相应的依赖即可
spring cloud提供了spring-cloud-sleuth-zipkin来方便集成zipkin实现（指的是Zipkin Client，而不是Zipkin服务器），该jar包可以通过spring-cloud-starter-zipkin依赖来引入
Zipkin是什么
Zipkin分布式跟踪系统；它可以帮助收集时间数据，解决在microservice架构下的延迟问题；它管理这些数据的收集和查找
为什么使用Zipkin
随着业务越来越复杂，系统也随之进行各种拆分，特别是随着微服务架构和容器技术的兴起，看似简单的一个应用，后台可能有几十个甚至几百个服务在支撑；一个前端的请求可能需要多次的服务调用最后才能完成；当请求变慢或者不可用时，我们无法得知是哪个后台服务引起的，这时就需要解决如何快速定位服务故障点，Zipkin分布式跟踪系统就能很好的解决这样的问题。
Zipkin原理
针对服务化应用全链路追踪的问题，Google发表了Dapper论文，介绍了他们如何进行服务追踪分析。其基本思路是在服务调用的请求和响应中加入ID，标明上下游请求的关系。利用这些信息，可以可视化地分析服务调用链路和服务间的依赖关系。
对应Dpper的开源实现是Zipkin，支持多种语言包括JavaScript，Python，Java, Scala, Ruby, C#, Go等。其中Java由多种不同的库来支持
Spring Cloud Sleuth是对Zipkin的一个封装，对于Span、Trace等信息的生成、接入HTTP Request，以及向Zipkin Server发送采集信息等全部自动完成
http://localhost:9411/
9.spring如何解决循环依赖
什么是循环依赖？
一个或者多个对象示例之间存在直接或者间接的依赖关系，这种依赖关系构成一个环形调用
Spring的解决：
 
三级缓存
singletonObjects 一级缓存，用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用
earlySingletonObjects 二级缓存，提前曝光的单例对象的cache，存放原始的 bean 对象（尚未填充属性），用于解决循环依赖
singletonFactories 三级缓存，单例对象工厂的cache，存放 bean 工厂对象，用于解决循环依赖
为什么要用三级而不是二级？
为了解决aop场景下的循环依赖。
其他循环依赖：
1，生成代理对象产生的循环依赖
解决：使用@Lazy注解，延迟加载
      使用@DependsOn注解，指定加载先后顺序
      修改文件名称，改变循环依赖类的加载顺序
2，使用@DependOn注解产生的循环依赖
   解决： 这类循环依赖找到@DependsOn注解循环依赖的i地方，迫使它不许循环依赖
3，多例循环依赖
   解决： 这类循环依赖可以通过把Bean改成单例解决
4，构造器循环依赖
   解决：使用@Lazy注解解决

10，hystrc配置
Fallback相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存.
feign.hystrix.enabled=true

11，jdk源码
12，springcloudconfig用mq，消息总线
使用消息总线spring cloud Bus 代理 rabbitMQ 自动刷新配置
原理：
spring cloud bus整合java的事件处理机制和消息中间件的发送和接收，主要是由发送端、接收端和事件组成。

目前spring cloud bus只实现了RabbitMq和Kafka的封装。

1.在config server中引入 spring cloud bus，将配置服务端也加入到消息总线中来；
2./bus/refresh请求不再发送到具体服务实例上，而是发送给Config Server,并通过destination参数指定需要更新配置的服务或实例。
